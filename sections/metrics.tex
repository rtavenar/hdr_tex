The definition of adequate metrics between objects to be compared is at the
core of many machine learning methods (\emph{eg.} nearest neighbors, kernel
machines, \emph{etc.}).
When complex objects are at stake, such metrics have to be carefully designed
in order to leverage desired notions of similarity.

This section covers my works related to the definition of new metrics for
structured data such as time series or graphs.
Three tracks are investigated.
First, in Sec.~\ref{sec:kernel}, time series are seen as discrete
distributions over the feature-time product space and a kernel is defined that
efficiently compares such representations.
Second, in Sec.~\ref{sec:dtw}, time series are treated as sequences, which
means that only ordering is of importance (time delay between observations
is ignored) and variants of the Dynamic Time Warping algorithm are used.
Finally, in Sec.~\ref{sec:ot}, undirected labeled graphs are seen as
discrete distributions over the feature-structure product space and we rely on
optimal transport distances.

\input{sections/01/temporal_kernel.tex}
\input{sections/01/dtw.tex}
\input{sections/01/ot.tex}
